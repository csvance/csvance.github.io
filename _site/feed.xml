<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>I'm an undergrad student exploring machine learning and artificial intelligence. In my spare time I enjoy cooking, writing music, running, and a cold pale ale.</description>
    <link>https://csvance.github.io/</link>
    <atom:link href="https://csvance.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 19 Dec 2017 21:45:16 -0600</pubDate>
    <lastBuildDate>Tue, 19 Dec 2017 21:45:16 -0600</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Next Steps: Recurrent Neural Networks</title>
        <description>&lt;p&gt;Over a period of several years I have been gradually developing a &lt;a href=&quot;https://en.wikipedia.org/wiki/Markov_chain&quot;&gt;Markov chain&lt;/a&gt; style chatbot called &lt;a href=&quot;https://github.com/csvance/armchair-expert&quot;&gt;armchair-expert&lt;/a&gt; which is intended to emulate the patterns of speech it sees in chat messages, tweets, or even books over time. From its humble beginnings using a hack-eyed Markov chain engine, to its current fairly powerful yet inefficient &lt;a href=&quot;https://en.wikipedia.org/wiki/Relational_database_management_system&quot;&gt;RDBMS&lt;/a&gt; incarnation, it has been slowly improving over time. Now is the time to make what I think is the next step in accuracy and performance: &lt;a href=&quot;https://en.wikipedia.org/wiki/Long_short-term_memory&quot;&gt;LSTM&lt;/a&gt; based &lt;a href=&quot;https://en.wikipedia.org/wiki/Recurrent_neural_network&quot;&gt;recurrent neural networks&lt;/a&gt;. However, there are certain potential problems I have been thinking about which make me hesitate fully committing to this approach when I could just create a &lt;a href=&quot;https://en.wikipedia.org/wiki/Trie&quot;&gt;trie&lt;/a&gt; style Markov chain which would have the same features as the current system with much higher performance.&lt;/p&gt;

&lt;h3 id=&quot;potential-problems&quot;&gt;Potential Problems&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;New Words - One reason I have hesitated moving to a word embedding neural network based solution in general was the difficulty incorporating newly encountered words without retraining the entire neural net. In theory however, we can set aside many unused embeddings for this purpose, and train the network in real time when new data is encountered.&lt;/li&gt;
  &lt;li&gt;Performance - Certain word embedding models require millions of variables with just a 10,000 word vocabulary and 300 feature hidden layer. I need to do more investigation into whether this is also a problem for RNN style nets.&lt;/li&gt;
  &lt;li&gt;Another problem in my initial investigations was the amount of training data required for vectorization of words. Algorithms like &lt;a href=&quot;https://en.wikipedia.org/wiki/Word2vec&quot;&gt;Word2Vec&lt;/a&gt; (Mikolov et. al) partially overcame this problem using negative sampling, but in my limited experience I was unable to create a useful vector space with 32,000 tweets with various rates of negative sampling. This may not be an issue due to the sequential nature of our data.&lt;/li&gt;
  &lt;li&gt;Subject Based Generation - Will an LSTM based RNN be able to generate a sentence based on several keywords or even a single subject? Sentences do not always start with a subject and are mostly built around it, rather than after it.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sat, 09 Dec 2017 16:27:00 -0600</pubDate>
        <link>https://csvance.github.io/update/armchair-expert/ml/ai/rnn/lstm/markov/armchair-expert-rnn.html</link>
        <guid isPermaLink="true">https://csvance.github.io/update/armchair-expert/ml/ai/rnn/lstm/markov/armchair-expert-rnn.html</guid>
        
        
        <category>update</category>
        
        <category>armchair-expert</category>
        
        <category>ml</category>
        
        <category>ai</category>
        
        <category>rnn</category>
        
        <category>lstm</category>
        
        <category>markov</category>
        
      </item>
    
      <item>
        <title>Hello World!</title>
        <description>&lt;p&gt;Hi, and welcome to my portfolio and blog. I will be chronicling my explorations in machine learning, artificial intelligence, and software engineering here.&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Dec 2017 13:40:48 -0600</pubDate>
        <link>https://csvance.github.io/update/hello-world.html</link>
        <guid isPermaLink="true">https://csvance.github.io/update/hello-world.html</guid>
        
        
        <category>update</category>
        
      </item>
    
  </channel>
</rss>
